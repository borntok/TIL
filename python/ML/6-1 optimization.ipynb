{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-1 NN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Graient Descent 최적화 구현"
      ],
      "metadata": {
        "id": "cBavyqsdlfmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nGmCQhssl0NT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실 함수 정의 (Analytic)"
      ],
      "metadata": {
        "id": "fHr7kbwjlll6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4SdOtZi9lZxT"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "  return 0.1*x**4 - 1.5*x**3 + 0.6*x**2 + 1.0*x + 20.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실 함수 미분 정의"
      ],
      "metadata": {
        "id": "ccJs7iFsl3o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def df_dx(x):\n",
        "  return 0.4*x**3 - 4.5*x**2 + 1.2*x +1.0"
      ],
      "metadata": {
        "id": "TlVKpu65l2zn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터 정의"
      ],
      "metadata": {
        "id": "u46TIaQQmEJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = 5\n",
        "eps = 1e-5\n",
        "lr = 0.01\n",
        "max_iter = 1000"
      ],
      "metadata": {
        "id": "eDAI4420l1zo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent 알고리즘 구현"
      ],
      "metadata": {
        "id": "p4e4lOtrmP1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_x = x\n",
        "min_y = f(min_x)\n",
        "\n",
        "for _ in range(max_iter):\n",
        "  grad = df_dx(x)\n",
        "  new_x = x - lr * grad\n",
        "  y = f(new_x)\n",
        "\n",
        "  if min_y > y :\n",
        "    min_x = new_x\n",
        "    min_y = y\n",
        "\n",
        "  if np.abs(x - new_x) < eps:\n",
        "    break\n",
        "\n",
        "  x = new_x"
      ],
      "metadata": {
        "id": "ECnORQB7mPPD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(min_x, min_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9qRevNYmxIp",
        "outputId": "a5d4d976-3b77-4aa9-b8fc-2c122456bc44"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.955323272631201 -428.84677390087836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "xV0RpaZRnYH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(initial_x, learning_rate=0.01, eps=1e-5, max_iter=1000):\n",
        "  x = initial_x\n",
        "\n",
        "  x_log = [x]\n",
        "\n",
        "  min_x = x\n",
        "  min_y = f(min_x)\n",
        "\n",
        "  for _ in range(max_iter):\n",
        "    grad = df_dx(x)\n",
        "    new_x = x - learning_rate * grad\n",
        "    y = f(new_x)\n",
        "\n",
        "    x_log.append(new_x)\n",
        "\n",
        "    if min_y > y :\n",
        "      min_x = new_x\n",
        "      min_y = y\n",
        "\n",
        "    if np.abs(x - new_x) < eps:\n",
        "      break\n",
        "\n",
        "    x = new_x\n",
        "\n",
        "  return min_x, min_y, x_log"
      ],
      "metadata": {
        "id": "KMTstcXVm2Is"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_x1, min_y1, x_log1 = gradient_descent(initial_x=5)\n",
        "min_x2, min_y2, x_log2 = gradient_descent(initial_x=-5)\n",
        "min_x3, min_y3, x_log3 = gradient_descent(initial_x=0)\n",
        "min_x4, min_y4, x_log4 = gradient_descent(initial_x=15, learning_rate=0.005)\n",
        "\n",
        "y_log1 = f(np.array(x_log1))\n",
        "y_log2 = f(np.array(x_log2))\n",
        "y_log3 = f(np.array(x_log3))\n",
        "y_log4 = f(np.array(x_log4))\n",
        "\n",
        "plt.plot(x_log1, y_log1, '.-')\n",
        "plt.plot(x_log2, y_log2, '.-')\n",
        "plt.plot(x_log3, y_log3, '.-')\n",
        "plt.plot(x_log4, y_log4, '.-')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2ls-oHEhoAwH",
        "outputId": "e6cd0e7b-a17f-47ea-ec58-f8221671fab4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 수치 미분을 이용한 심층 신경망 학습"
      ],
      "metadata": {
        "id": "IF8ot5_TCq9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "Ah5iXpQ1ouJ2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 유틸리티 함수"
      ],
      "metadata": {
        "id": "zYx92qbACw9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 0.0001\n",
        "\n",
        "def _t(x):\n",
        "  return np.transpose(x)\n",
        "\n",
        "def _m(A, B):\n",
        "  return np.matmul(A, B)\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def mean_squared_error(h, y):\n",
        "  return 1 / 2 * np.mean(np.square(h - y))"
      ],
      "metadata": {
        "id": "i7Ri9enfCwJG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 뉴런 구현"
      ],
      "metadata": {
        "id": "8da0DTFTDKwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.numeric import zeros_like\n",
        "class Dense:\n",
        "  def __init__(self, W, b, a):\n",
        "    self.W = W\n",
        "    self.b = b\n",
        "    self.a = a\n",
        "\n",
        "    self.dW = np.zeros_like(self.W)\n",
        "    self.db = np.zeros_like(self.b)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.a(_m(_t(self.W), x) + self.b)"
      ],
      "metadata": {
        "id": "gYmG_QGiDKJQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 심층신경망 구현"
      ],
      "metadata": {
        "id": "ZwjUlouxDdy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN:\n",
        "  def __init__(self, hidden_depth, num_neuron, num_input, num_output, activation=sigmoid):\n",
        "    def init_var(i, o):\n",
        "      return np.random.normal(0.0, 0.01, (i, o)), np.zeros((o,))\n",
        "\n",
        "    self.sequence = list()\n",
        "    # First hidden layer\n",
        "    W, b = init_var(num_input, num_neuron)\n",
        "    self.sequence.append(Dense(W, b, activation))\n",
        "\n",
        "    # Hidden layers\n",
        "    for _ in range(hidden_depth-1):\n",
        "      W, b = init_var(num_neuron, num_neuron)\n",
        "      self.sequence.append(Dense(W, b, activation))\n",
        "\n",
        "    # Output layer\n",
        "    W, b = init_var(num_neuron, num_output)\n",
        "    self.sequence.append(Dense(W, b, activation))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.sequence:\n",
        "      x = layer(x)\n",
        "    return x\n",
        "\n",
        "  def calc_gradient(self, x, y, loss_func):\n",
        "    def get_new_sequence(layer_index, new_layer):\n",
        "      new_sequence = list()\n",
        "      for i, layer in enumerate(self.sequence):\n",
        "        if i == layer_index:\n",
        "          new_sequence.append(new_layer)\n",
        "        else:\n",
        "          new_sequence.append(layer)\n",
        "      return new_sequence\n",
        "\n",
        "    def eval_sequence(x, sequence):\n",
        "      for layer in sequence:\n",
        "        x = layer(x)\n",
        "      return x\n",
        "\n",
        "    loss = loss_func(self(x), y)\n",
        "\n",
        "    for layer_id, layer in enumerate(self.sequence):\n",
        "      for w_i, w in enumerate(layer.W):\n",
        "        for w_j, ww in enumerate(w):\n",
        "          W = np.copy(layer.W)\n",
        "          W[w_i][w_j] = ww + epsilon\n",
        "\n",
        "          new_layer = Dense(W, layer.b, layer.a)\n",
        "          new_seq = get_new_sequence(layer_id, new_layer)\n",
        "          h = eval_sequence(x, new_seq)\n",
        "\n",
        "          num_grad = (loss_func(h, y) - loss) / epsilon # (f(x+eps) - f(x)) / eps\n",
        "          layer.dW[w_i][w_j] = num_grad\n",
        "\n",
        "      for b_i, bb in enumerate(layer.b):\n",
        "          b = np.copy(layer.b)\n",
        "          b[b_i] = bb + epsilon\n",
        "\n",
        "          new_layer = Dense(layer.W, b, layer.a)\n",
        "          new_seq = get_new_sequence(layer_id, new_layer)\n",
        "          h = eval_sequence(x, new_seq)\n",
        "\n",
        "          num_grad = (loss_func(h, y) - loss) / epsilon # (f(x+eps) - f(x)) / eps\n",
        "          layer.db[b_i] = num_grad\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "Elem2Tk0DfLL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 경사하강 학습법"
      ],
      "metadata": {
        "id": "yD26_y9j4pMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(network, x, y, loss_obj, alpha=0.01):\n",
        "  loss = network.calc_gradient(x, y, loss_obj)\n",
        "  for layer in network.sequence:\n",
        "    layer.W += -alpha * layer.dW\n",
        "    layer.b += -alpha * layer.db\n",
        "  return loss"
      ],
      "metadata": {
        "id": "0g0toqhq4q2w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 동작 테스트"
      ],
      "metadata": {
        "id": "cGMqIyz45B0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.random.normal(0.0, 1.0, (10,))\n",
        "y = np.random.normal(0.0, 1.0, (2,))\n",
        "\n",
        "dnn = DNN(hidden_depth=10, num_neuron=32, num_input=10, num_output=2, activation=sigmoid)\n",
        "\n",
        "t = time.time()\n",
        "\n",
        "for epoch in range(100):\n",
        "  loss = gradient_descent(dnn, x, y, mean_squared_error, 0.01)\n",
        "  print(f'Epoch {epoch}: Test loss {loss}')\n",
        "print(f'{time.time() - t} seconds elapsed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gislxph85Arp",
        "outputId": "9fb2a31c-ddcf-4463-fb47-09c039baa1f5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Test loss 0.8909169577281527\n",
            "Epoch 1: Test loss 0.8859158064490396\n",
            "Epoch 2: Test loss 0.8809428785938215\n",
            "Epoch 3: Test loss 0.8759990911317044\n",
            "Epoch 4: Test loss 0.871085327538994\n",
            "Epoch 5: Test loss 0.8662024372498569\n",
            "Epoch 6: Test loss 0.8613512351940795\n",
            "Epoch 7: Test loss 0.8565325014227139\n",
            "Epoch 8: Test loss 0.8517469808190279\n",
            "Epoch 9: Test loss 0.8469953828933816\n",
            "Epoch 10: Test loss 0.8422783816602645\n",
            "Epoch 11: Test loss 0.8375966155953063\n",
            "Epoch 12: Test loss 0.8329506876690087\n",
            "Epoch 13: Test loss 0.8283411654553323\n",
            "Epoch 14: Test loss 0.8237685813111957\n",
            "Epoch 15: Test loss 0.8192334326247535\n",
            "Epoch 16: Test loss 0.8147361821276795\n",
            "Epoch 17: Test loss 0.8102772582697204\n",
            "Epoch 18: Test loss 0.8058570556501715\n",
            "Epoch 19: Test loss 0.8014759355041439\n",
            "Epoch 20: Test loss 0.7971342262386161\n",
            "Epoch 21: Test loss 0.7928322240153858\n",
            "Epoch 22: Test loss 0.7885701933766247\n",
            "Epoch 23: Test loss 0.7843483679099246\n",
            "Epoch 24: Test loss 0.7801669509481637\n",
            "Epoch 25: Test loss 0.7760261163015514\n",
            "Epoch 26: Test loss 0.7719260090174999\n",
            "Epoch 27: Test loss 0.7678667461650943\n",
            "Epoch 28: Test loss 0.7638484176408779\n",
            "Epoch 29: Test loss 0.7598710869923142\n",
            "Epoch 30: Test loss 0.7559347922560828\n",
            "Epoch 31: Test loss 0.7520395468079484\n",
            "Epoch 32: Test loss 0.7481853402210366\n",
            "Epoch 33: Test loss 0.7443721391303609\n",
            "Epoch 34: Test loss 0.7405998881004461\n",
            "Epoch 35: Test loss 0.7368685104936084\n",
            "Epoch 36: Test loss 0.7331779093368285\n",
            "Epoch 37: Test loss 0.7295279681846567\n",
            "Epoch 38: Test loss 0.725918551976301\n",
            "Epoch 39: Test loss 0.7223495078851735\n",
            "Epoch 40: Test loss 0.7188206661586901\n",
            "Epoch 41: Test loss 0.7153318409473154\n",
            "Epoch 42: Test loss 0.7118828311207913\n",
            "Epoch 43: Test loss 0.7084734210707895\n",
            "Epoch 44: Test loss 0.7051033814983545\n",
            "Epoch 45: Test loss 0.7017724701854604\n",
            "Epoch 46: Test loss 0.698480432749329\n",
            "Epoch 47: Test loss 0.6952270033791836\n",
            "Epoch 48: Test loss 0.6920119055544562\n",
            "Epoch 49: Test loss 0.6888348527437373\n",
            "Epoch 50: Test loss 0.6856955490844475\n",
            "Epoch 51: Test loss 0.6825936900423141\n",
            "Epoch 52: Test loss 0.6795289630507002\n",
            "Epoch 53: Test loss 0.6765010481294793\n",
            "Epoch 54: Test loss 0.6735096184832005\n",
            "Epoch 55: Test loss 0.6705543410788222\n",
            "Epoch 56: Test loss 0.6676348772024893\n",
            "Epoch 57: Test loss 0.6647508829958972\n",
            "Epoch 58: Test loss 0.6619020099722046\n",
            "Epoch 59: Test loss 0.6590879055114789\n",
            "Epoch 60: Test loss 0.656308213336349\n",
            "Epoch 61: Test loss 0.6535625739675328\n",
            "Epoch 62: Test loss 0.6508506251600601\n",
            "Epoch 63: Test loss 0.6481720023202722\n",
            "Epoch 64: Test loss 0.6455263389039599\n",
            "Epoch 65: Test loss 0.6429132667961497\n",
            "Epoch 66: Test loss 0.640332416672857\n",
            "Epoch 67: Test loss 0.6377834183451473\n",
            "Epoch 68: Test loss 0.6352659010863091\n",
            "Epoch 69: Test loss 0.632779493942069\n",
            "Epoch 70: Test loss 0.6303238260248283\n",
            "Epoch 71: Test loss 0.6278985267920085\n",
            "Epoch 72: Test loss 0.6255032263092294\n",
            "Epoch 73: Test loss 0.623137555498682\n",
            "Epoch 74: Test loss 0.6208011463732791\n",
            "Epoch 75: Test loss 0.6184936322570405\n",
            "Epoch 76: Test loss 0.6162146479919935\n",
            "Epoch 77: Test loss 0.6139638301324923\n",
            "Epoch 78: Test loss 0.6117408171270388\n",
            "Epoch 79: Test loss 0.609545249488239\n",
            "Epoch 80: Test loss 0.6073767699514849\n",
            "Epoch 81: Test loss 0.6052350236224755\n",
            "Epoch 82: Test loss 0.6031196581144243\n",
            "Epoch 83: Test loss 0.6010303236750972\n",
            "Epoch 84: Test loss 0.5989666733042895\n",
            "Epoch 85: Test loss 0.5969283628620345\n",
            "Epoch 86: Test loss 0.5949150511680136\n",
            "Epoch 87: Test loss 0.5929264000926839\n",
            "Epoch 88: Test loss 0.5909620746402056\n",
            "Epoch 89: Test loss 0.5890217430238692\n",
            "Epoch 90: Test loss 0.5871050767342396\n",
            "Epoch 91: Test loss 0.5852117506003387\n",
            "Epoch 92: Test loss 0.58334144284433\n",
            "Epoch 93: Test loss 0.5814938351298752\n",
            "Epoch 94: Test loss 0.5796686126046191\n",
            "Epoch 95: Test loss 0.577865463937121\n",
            "Epoch 96: Test loss 0.5760840813483429\n",
            "Epoch 97: Test loss 0.574324160638271\n",
            "Epoch 98: Test loss 0.5725854012076296\n",
            "Epoch 99: Test loss 0.5708675060752346\n",
            "163.14430475234985 seconds elapsed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0S_OF5j5N6o_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}